name: Enhanced Security Pipeline with Self-Hosted Runner
on: 
  push:
    branches: [main, master, develop]
  pull_request:
    branches: [main, master]

permissions:
  contents: read
  issues: write
  pull-requests: write
  actions: read

jobs:
  build:
    runs-on: ubuntu-latest  # Use GitHub's runners for regular builds
    name: Run unit tests and SAST scan on the source code 
    outputs:
      sonar-results: ${{ steps.sonar-scan.outputs.report-path }}
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up JDK 21
      uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: 'zulu'
        cache: maven
    
    - name: Run Maven Tests
      run: mvn clean test
    
    - name: Run Sonar Analysis with cloud
      id: sonar-scan
      run: |
        mvn -B verify sonar:sonar \
          -Dsonar.projectKey=testtraining_testtraining \
          -Dsonar.organization=testtraining \
          -Dsonar.host.url=https://sonarcloud.io \
          -Dsonar.token=$SONAR_TOKEN
        
        # Download SonarCloud results
        sleep 30
        curl -u "$SONAR_TOKEN:" \
          "https://sonarcloud.io/api/issues/search?componentKeys=testtraining_testtraining&resolved=false" \
          -o sonar-results.json || echo '{"issues":[]}' > sonar-results.json
        
        echo "report-path=sonar-results.json" >> $GITHUB_OUTPUT
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
    
    - name: Upload SonarQube Results
      uses: actions/upload-artifact@v4
      with:
        name: sonar-results
        path: sonar-results.json

  security:
    runs-on: ubuntu-latest  # Use GitHub's runners for security scans
    needs: build
    name: Run the SCA scan on the source code
    outputs:
      snyk-results: ${{ steps.snyk-scan.outputs.report-path }}
    steps:
      - uses: actions/checkout@master
      
      - name: Run Snyk to check for vulnerabilities
        id: snyk-scan
        uses: snyk/actions/maven@master
        continue-on-error: true
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --json-file-output=snyk-results.json
      
      - name: Upload Snyk Results
        uses: actions/upload-artifact@v4
        with:
          name: snyk-results
          path: snyk-results.json

  zap_scan:
    runs-on: ubuntu-latest  # Use GitHub's runners for ZAP scan
    needs: security
    name: Run DAST scan on the web application
    outputs:
      zap-results: ${{ steps.zap-scan.outputs.report-path }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: master
      
      - name: ZAP Scan
        id: zap-scan
        uses: zaproxy/action-baseline@v0.14.0
        with:
          target: 'http://testphp.vulnweb.com/'
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a -J zap-report.json'
      
      - name: Upload ZAP Results
        uses: actions/upload-artifact@v4
        with:
          name: zap-results
          path: zap-report.json

  # AI Analysis using self-hosted runner with local Ollama
  ai_security_analysis:
    runs-on: self-hosted  # This runs on YOUR server with Ollama
    needs: [build, security, zap_scan]
    name: AI-Powered Security Analysis (Local Ollama)
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Python
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install requests
      
      - name: Download all scan results
        uses: actions/download-artifact@v4
        with:
          path: scan-results/
      
      - name: Check Local Ollama
        run: |
          echo "üîç Checking local Ollama status..."
          
          # Check if ollama process is running
          if pgrep -x "ollama" > /dev/null; then
            echo "‚úÖ Ollama process is running"
          else
            echo "‚ö†Ô∏è  Ollama not running, starting it..."
            ollama serve &
            sleep 10
          fi
          
          # Test local connection
          if curl -s -m 5 http://localhost:11434/api/tags > /dev/null; then
            echo "‚úÖ Ollama API is responding"
          else
            echo "‚ùå Ollama API not responding"
            exit 1
          fi
          
          # Check if Mistral model is available
          if ollama list | grep -q "mistral"; then
            echo "‚úÖ Mistral model is available"
            ollama list | grep mistral
          else
            echo "‚ö†Ô∏è  Mistral model not found, pulling it..."
            ollama pull mistral:latest
          fi
      
      - name: Create Security Context
        run: |
          cat > security-context.json << EOF
          {
            "business_criticality": "high",
            "compliance_requirements": ["SOC2", "OWASP"],
            "attack_surface": ["web_application", "api_endpoints"],
            "environment": "production",
            "risk_tolerance": "low",
            "critical_assets": ["user_authentication", "user_database"],
            "remediation_sla": {
              "critical": "24_hours",
              "high": "72_hours",
              "medium": "7_days",
              "low": "30_days"
            }
          }
          EOF
      
      - name: Create AI Security Agent
        run: |
          cat > ai_security_agent.py << 'EOF'
          import json
          import requests
          import sys
          import os
          import time
          from typing import Dict, List

          class LocalOllamaAgent:
              def __init__(self):
                  self.host = "http://localhost:11434"  # Always use localhost on self-hosted runner
                  self.model = "mistral:latest"
                  print(f"ü§ñ Using local Ollama at: {self.host}")
                  self.context = self.load_security_context()
              
              def load_security_context(self):
                  try:
                      with open('security-context.json', 'r') as f:
                          return json.load(f)
                  except FileNotFoundError:
                      return {"business_criticality": "medium"}
              
              def query_mistral(self, prompt: str, max_retries=3) -> str:
                  for attempt in range(max_retries):
                      try:
                          payload = {
                              "model": self.model,
                              "prompt": prompt,
                              "stream": False,
                              "options": {
                                  "temperature": 0.1,
                                  "num_ctx": 4096,
                                  "num_predict": 1024
                              }
                          }
                          
                          print(f"üîÑ Querying local Mistral (attempt {attempt + 1})...")
                          response = requests.post(f"{self.host}/api/generate", json=payload, timeout=300)
                          response.raise_for_status()
                          
                          result = response.json().get("response", "")
                          print(f"‚úÖ Received response ({len(result)} characters)")
                          return result
                          
                      except Exception as e:
                          print(f"‚ùå Error (attempt {attempt + 1}): {e}")
                          if attempt < max_retries - 1:
                              time.sleep(5)
                          else:
                              return f"Local AI analysis failed: {str(e)}"
                  
                  return "Failed to get AI analysis after multiple attempts"
              
              def analyze_security_findings(self, findings_summary):
                  prompt = f"""As a cybersecurity expert, analyze these security findings:

          Business Context:
          - Criticality: {self.context.get('business_criticality', 'medium')}
          - Compliance: {', '.join(self.context.get('compliance_requirements', []))}
          - Risk Tolerance: {self.context.get('risk_tolerance', 'medium')}

          Security Findings ({len(findings_summary)} total):
          {json.dumps(findings_summary, indent=2)}

          Provide a JSON analysis with these keys:
          1. "risk_summary": Overall risk assessment (1-2 sentences)
          2. "top_priorities": Top 3 findings with business impact scores (1-10)
          3. "recommendations": 3 specific actionable recommendations

          Respond ONLY with valid JSON, no additional text."""
                  
                  return self.query_mistral(prompt)

          def parse_scan_results():
              findings = []
              
              # Parse SonarQube results
              try:
                  with open('scan-results/sonar-results/sonar-results.json', 'r') as f:
                      sonar_data = json.load(f)
                      for issue in sonar_data.get('issues', [])[:10]:
                          findings.append({
                              "tool": "SonarQube",
                              "severity": issue.get('severity', 'UNKNOWN'),
                              "vulnerability": issue.get('rule', 'Unknown Rule'),
                              "file": issue.get('component', '').replace('testtraining_testtraining:', ''),
                              "line": issue.get('line', 0),
                              "description": issue.get('message', '')[:200]
                          })
              except Exception as e:
                  print(f"‚ö†Ô∏è  Error parsing SonarQube results: {e}")
              
              # Parse Snyk results
              try:
                  with open('scan-results/snyk-results/snyk-results.json', 'r') as f:
                      snyk_data = json.load(f)
                      for vuln in snyk_data.get('vulnerabilities', [])[:5]:
                          findings.append({
                              "tool": "Snyk",
                              "severity": vuln.get('severity', 'unknown'),
                              "vulnerability": vuln.get('title', 'Unknown Vulnerability'),
                              "description": vuln.get('description', '')[:200],
                              "cvss": vuln.get('cvssScore', 0.0)
                          })
              except Exception as e:
                  print(f"‚ö†Ô∏è  Error parsing Snyk results: {e}")
              
              # Parse ZAP results
              try:
                  with open('scan-results/zap-results/zap-report.json', 'r') as f:
                      zap_data = json.load(f)
                      site_data = zap_data.get('site', [{}])[0] if zap_data.get('site') else {}
                      for alert in site_data.get('alerts', [])[:5]:
                          findings.append({
                              "tool": "ZAP",
                              "severity": alert.get('riskdesc', 'Unknown Risk'),
                              "vulnerability": alert.get('name', 'Unknown Alert'),
                              "url": alert.get('url', ''),
                              "description": alert.get('desc', '')[:200]
                          })
              except Exception as e:
                  print(f"‚ö†Ô∏è  Error parsing ZAP results: {e}")
              
              return findings

          def main():
              print("üöÄ Starting Local AI Security Analysis...")
              
              # Parse security findings
              findings = parse_scan_results()
              print(f"üìä Found {len(findings)} security findings across all tools")
              
              if not findings:
                  print("‚ö†Ô∏è  No security findings to analyze")
                  final_results = {
                      "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
                      "total_findings": 0,
                      "ai_analysis": "No security findings to analyze",
                      "status": "success"
                  }
              else:
                  # Initialize AI agent
                  agent = LocalOllamaAgent()
                  
                  # Run AI analysis
                  print("ü§ñ Running local AI analysis...")
                  ai_response = agent.analyze_security_findings(findings)
                  
                  # Try to parse AI response as JSON
                  try:
                      ai_analysis = json.loads(ai_response)
                  except:
                      ai_analysis = {
                          "risk_summary": "AI analysis completed but response was not in expected format",
                          "raw_response": ai_response[:500]
                      }
                  
                  # Create final results
                  final_results = {
                      "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
                      "total_findings": len(findings),
                      "tools_used": list(set(f.get('tool') for f in findings)),
                      "ai_analysis": ai_analysis,
                      "findings_sample": findings[:3],
                      "status": "success"
                  }
              
              # Save results
              with open('ai-analysis-results.json', 'w') as f:
                  json.dump(final_results, f, indent=2)
              
              print("‚úÖ Local AI Security Analysis Complete!")
              print("üìÑ Results saved to ai-analysis-results.json")

          if __name__ == "__main__":
              main()
          EOF
      
      - name: Run AI Security Analysis
        run: |
          python3 ai_security_agent.py
      
      - name: Generate Executive Summary
        run: |
          python3 -c "
          import json
          from datetime import datetime
          
          try:
              with open('ai-analysis-results.json', 'r') as f:
                  results = json.load(f)
          except:
              results = {'ai_analysis': 'Failed to load results'}
          
          summary = f'''# ü§ñ AI Security Analysis Summary (Local Ollama)
          
          **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
          **Total Findings:** {results.get('total_findings', 0)}
          **Tools:** {', '.join(results.get('tools_used', []))}
          **Status:** {results.get('status', 'unknown')}
          **AI Engine:** Local Mistral on Self-Hosted Runner
          
          ## Risk Assessment
          {results.get('ai_analysis', {}).get('risk_summary', 'Analysis not available')}
          
          ## Top Priorities
          '''
          
          priorities = results.get('ai_analysis', {}).get('top_priorities', [])
          if isinstance(priorities, list):
              for i, priority in enumerate(priorities[:3], 1):
                  if isinstance(priority, dict):
                      summary += f'{i}. **{priority.get(\"vulnerability\", \"Unknown\")}** (Impact: {priority.get(\"business_impact\", \"N/A\")})\n'
                  else:
                      summary += f'{i}. {priority}\n'
          
          recommendations = results.get('ai_analysis', {}).get('recommendations', [])
          if recommendations:
              summary += '\n## Recommendations\n'
              for i, rec in enumerate(recommendations[:3], 1):
                  summary += f'{i}. {rec}\n'
          
          with open('executive-summary.md', 'w') as f:
              f.write(summary)
          "
      
      - name: Upload AI Analysis Results
        uses: actions/upload-artifact@v4
        with:
          name: ai-analysis-results
          path: |
            ai-analysis-results.json
            executive-summary.md
      
      - name: Comment on PR with AI Analysis
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            try {
              const summary = fs.readFileSync('executive-summary.md', 'utf8');
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: summary
              });
            } catch (error) {
              console.log('Error posting comment:', error);
            }
